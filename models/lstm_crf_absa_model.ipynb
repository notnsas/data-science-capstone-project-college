{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/notnsas/data-science-capstone-project-college/blob/main/models/lstm_crf_absa_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "938de1c8-c6da-4f5e-bc6d-391bbe5b80e1",
      "metadata": {
        "id": "938de1c8-c6da-4f5e-bc6d-391bbe5b80e1",
        "outputId": "c3e63edb-833b-40f1-bed8-4278a32bbee6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\anaconda3\\envs\\capstone\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files={\n",
        "        \"train\": r\"D:\\Code\\Capstone\\dataset\\absa_train.json\",\n",
        "        \"test\":  r\"D:\\Code\\Capstone\\dataset\\absa_test.json\"\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4290e5c3-e2a4-476a-90da-63518fb1746e",
      "metadata": {
        "id": "4290e5c3-e2a4-476a-90da-63518fb1746e",
        "outputId": "b44aeb71-f221-4273-c269-c5816c08f3ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 5, 6]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def find_sequence(lst, seq):\n",
        "    for i in range(len(lst) - len(seq) + 1):\n",
        "        match = True\n",
        "        for j in range(len(seq)):\n",
        "            if seq[j] not in lst[i + j]:\n",
        "                match = False\n",
        "                break\n",
        "        if match:\n",
        "            return i, i + len(seq)\n",
        "    return -1\n",
        "def labeling_ner(batch):\n",
        "    labels = []\n",
        "    batch = batch\n",
        "    tokens = batch['token']\n",
        "    # print(f'token : {tokens}')\n",
        "    # # for i, tokens in enumerate(batch['token']):\n",
        "    # print(\"\\n\" + \"-\"*60)\n",
        "    # print(f\"ðŸ”¹ Sample {i}\")\n",
        "    # print(\"-\"*60)\n",
        "\n",
        "    # Create default label 0 (O-tag)\n",
        "    label = [0] * len(tokens)\n",
        "\n",
        "    # Mark aspect terms with proper label IDs\n",
        "    # aspects = batch[\"aspects\"][i]\n",
        "    aspects = batch[\"aspects\"]\n",
        "    for aspect in aspects:\n",
        "        # start_id, end_id = aspect['from'], aspect['to']\n",
        "        t = aspect\n",
        "        # print(f'aspect : {t}')\n",
        "        term = aspect[\"term\"].split()\n",
        "        # print(f'term : {term}')\n",
        "        # print(f'find_sequence : {find_sequence(tokens, term)}')\n",
        "        ind_term = find_sequence(tokens, term)\n",
        "        # print(f'ind term : {ind_term}')\n",
        "        if ind_term == -1:\n",
        "            continue\n",
        "        start_id, end_id = ind_term\n",
        "        polarity = aspect['sentiment']\n",
        "\n",
        "        if polarity == 'Positive':\n",
        "            label[start_id] = 1  # B-POS\n",
        "            label[start_id + 1:end_id] = [2] * (end_id - start_id - 1)  # I-POS\n",
        "        elif polarity == 'Negative':\n",
        "            label[start_id] = 3  # B-NEG\n",
        "            label[start_id + 1:end_id] = [4] * (end_id - start_id - 1)  # I-NEG\n",
        "        elif polarity == 'Neutral':\n",
        "            label[start_id] = 5  # B-NEU\n",
        "            label[start_id + 1:end_id] = [6] * (end_id - start_id - 1)  # I-NEU\n",
        "    return label\n",
        "labeling_ner(dataset['train'][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15175100-d6ab-457b-a413-0899a3f706f6",
      "metadata": {
        "id": "15175100-d6ab-457b-a413-0899a3f706f6"
      },
      "outputs": [],
      "source": [
        "# dataset['train']['token'][2]\n",
        "# datass = dataset['train'][0]\n",
        "# labeling_ner(datass)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa3942eb-b62f-4dee-bab3-0f4c931aa3bb",
      "metadata": {
        "id": "aa3942eb-b62f-4dee-bab3-0f4c931aa3bb"
      },
      "outputs": [],
      "source": [
        "# dataset['train']['token'][3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d24ad647-a3a0-4404-bb67-96ee47319579",
      "metadata": {
        "id": "d24ad647-a3a0-4404-bb67-96ee47319579"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def load_glove(path, embedding_dim=100):\n",
        "    vocab_stoi = {}\n",
        "    embeddings = []\n",
        "\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for idx, line in enumerate(f):\n",
        "            parts = line.strip().split()\n",
        "            word = parts[0]\n",
        "            vector = torch.tensor([float(x) for x in parts[1:]], dtype=torch.float)\n",
        "\n",
        "            vocab_stoi[word] = idx\n",
        "            embeddings.append(vector)\n",
        "\n",
        "    # Add <pad> and <unk>\n",
        "    vocab_stoi['<pad>'] = len(embeddings)\n",
        "    embeddings.append(torch.zeros(embedding_dim))\n",
        "\n",
        "    vocab_stoi['<unk>'] = len(embeddings)\n",
        "    embeddings.append(torch.randn(embedding_dim) * 0.01)\n",
        "\n",
        "    embedding_matrix = torch.stack(embeddings)\n",
        "    return vocab_stoi, embedding_matrix\n",
        "\n",
        "vocab_stoi, embedding_matrix = load_glove(\"D:/Code/Capstone/ATE/ABSA_LSTM-CRF-master/glove.6B.100d.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ed51eba-b74b-4d97-83f3-9392fb519958",
      "metadata": {
        "id": "4ed51eba-b74b-4d97-83f3-9392fb519958"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class NLPDataset(Dataset):\n",
        "    def __init__(self, data, labeling_ner, vocab_stoi):\n",
        "        self.data = data\n",
        "        self.labeling_ner = labeling_ner\n",
        "        self.vocab_stoi = vocab_stoi\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        tokens = self.data['token'][idx]\n",
        "        token_ids = [self.vocab_stoi.get(w, self.vocab_stoi[\"<unk>\"]) for w in tokens]\n",
        "        # token_ids = torch.tensor([self.word_to_ix[w] for w in tokens], dtype=torch.long)\n",
        "        tags_ids = self.labeling_ner(self.data[idx])\n",
        "        return token_ids, tags_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "414dce8f-564d-4691-ba87-c6dacc224824",
      "metadata": {
        "id": "414dce8f-564d-4691-ba87-c6dacc224824"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # batch: list of (tokens, tags)|\n",
        "    tokens_batch, tags_batch = zip(*batch)\n",
        "    # tokens_batch = [[vocab_stoi.get(w, vocab_stoi[\"<unk>\"]) for w in seq] for seq in tokens_batch]\n",
        "    tokens_batch = [torch.tensor(t) for t in tokens_batch]\n",
        "    tags_batch = [torch.tensor(t) for t in tags_batch]\n",
        "\n",
        "    # convert each sequence to tensor\n",
        "    # tokens_batch_tensors = [torch.tensor(seq, dtype=torch.long) for seq in tokens_batch]\n",
        "    # tags_batch_tensors   = [torch.tensor(seq, dtype=torch.long) for seq in tags_batch]\n",
        "\n",
        "    # pad sequences to same length\n",
        "    tokens_padded = pad_sequence(tokens_batch, batch_first=True, padding_value=0)\n",
        "    tags_padded   = pad_sequence(tags_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "    # create mask\n",
        "    mask = tokens_padded != 0\n",
        "\n",
        "    return tokens_padded, tags_padded, mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bcd3354-6c0b-45b2-a3b4-cd849ac19030",
      "metadata": {
        "id": "6bcd3354-6c0b-45b2-a3b4-cd849ac19030"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader\n",
        "# # train_dataset = NLPDataset(dataset[\"train\"],labeling_ner, vocab_stoi)\n",
        "# # loader_train = DataLoader(train_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
        "# i = 0\n",
        "# # get first batch\n",
        "# for batch in loader_train:\n",
        "#     tokens_batch, tags_batch, mask = batch\n",
        "#     # print(\"Tokens batch shape:\", tokens_batch)\n",
        "#     # print(\"Tags batch shape  :\", tags_batch)\n",
        "#     # print(\"Mask shape        :\", mask)\n",
        "#     if i == 3:\n",
        "#         break  # just take the first batch\n",
        "#     i +=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b3f3403-41ca-4ac3-a76e-6420ab66fb8c",
      "metadata": {
        "id": "5b3f3403-41ca-4ac3-a76e-6420ab66fb8c"
      },
      "outputs": [],
      "source": [
        "# small = dataset['train'].select(range(500))\n",
        "# small[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e4e863d-446c-41c2-ab62-566ff2e92e13",
      "metadata": {
        "id": "6e4e863d-446c-41c2-ab62-566ff2e92e13"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Training dataset & DataLoader  .select(range(500))\n",
        "# ---------------------------\n",
        "small_train_data = dataset['train']\n",
        "dataset_train = NLPDataset(small_train_data, labeling_ner, vocab_stoi)\n",
        "loader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# Test dataset & DataLoader .select(range(200))\n",
        "# ---------------------------\n",
        "small_test_data = dataset['test']\n",
        "dataset_test = NLPDataset(small_test_data, labeling_ner, vocab_stoi)\n",
        "loader_test = DataLoader(\n",
        "    dataset_test,\n",
        "    batch_size=64,\n",
        "    shuffle=False,  # no shuffle for testing\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "# # get the first batch\n",
        "# batch = next(iter(train))\n",
        "\n",
        "# # if your dataset returns (tokens, tags)\n",
        "# tokens_batch, tags_batch, mask = batch\n",
        "\n",
        "# # print first element in the batch (index 0)\n",
        "# print(\"Tokens:\", tokens_batch[3])\n",
        "# print(\"Tags:  \", tags_batch[3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10fe8456-e355-4d1e-9b57-f1f197269a78",
      "metadata": {
        "id": "10fe8456-e355-4d1e-9b57-f1f197269a78"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchcrf import CRF\n",
        "\n",
        "class LSTM_CRF(nn.Module):\n",
        "    def __init__(self, tags):\n",
        "        super().__init__()\n",
        "        # self.embedding = nn.Embedding(10,25)\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
        "        self.lstm = nn.LSTM(100, 5, bidirectional=True, batch_first=True, dropout=0.1)\n",
        "        self.fc = nn.Linear(10, tags)\n",
        "        self.crf = CRF(tags, batch_first=True)\n",
        "\n",
        "    def forward(self, x, tags=None, mask=None):\n",
        "        x = self.__emissions(x)\n",
        "        # print(f\"Mask:\\n{mask}\")\n",
        "        if tags == None:\n",
        "            x = self.crf.decode(x)\n",
        "        else:\n",
        "            x = self.crf.decode(x, mask=mask)\n",
        "        return x\n",
        "\n",
        "    def __emissions(self, x):\n",
        "        x = self.embedding(x)\n",
        "        # print(f'emb : {x.shape}')\n",
        "        x, (h, c) = self.lstm(x)\n",
        "        # print(f'x:{x.shape}')\n",
        "        x = self.fc(x)\n",
        "        # print(f'fc:{x}')\n",
        "        return x\n",
        "\n",
        "    def loss(self, x, tags, mask=None):\n",
        "        # print('strart')\n",
        "        x = self.__emissions(x)\n",
        "        # print(f\"Tags:\\n{tags}\")\n",
        "        # print(f\"Mask:\\n{mask}\")\n",
        "        # print(f\"Tokens:\\n{x}\")\n",
        "\n",
        "        x = -self.crf(x, tags, mask=mask, reduction=\"mean\")\n",
        "        return x\n",
        "model = LSTM_CRF(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4d45da7-aec1-42c1-9e20-015b5d164ceb",
      "metadata": {
        "id": "d4d45da7-aec1-42c1-9e20-015b5d164ceb"
      },
      "outputs": [],
      "source": [
        "# from datasets import load_dataset\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# import torch\n",
        "\n",
        "# # ---------------------------\n",
        "# # Load CoNLL-2003\n",
        "# # ---------------------------\n",
        "# dataset = load_dataset(\"lhoestq/conll2003\")\n",
        "\n",
        "# # Build vocabulary and label mapping\n",
        "# all_tokens = [t for split in [\"train\",\"validation\",\"test\"] for sent in dataset[split][\"tokens\"] for t in sent]\n",
        "# vocab = list(set(all_tokens))\n",
        "# vocab_stoi = {tok:i+2 for i, tok in enumerate(vocab)}  # +2 for <pad>=0, <unk>=1\n",
        "# vocab_stoi[\"<pad>\"] = 0\n",
        "# vocab_stoi[\"<unk>\"] = 1\n",
        "# vocab_itos = {i:tok for tok,i in vocab_stoi.items()}\n",
        "\n",
        "# # Label mapping\n",
        "# # labels = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
        "# # tag_to_ix = {label:i for i,label in enumerate(labels)}\n",
        "# # ix_to_tag = {i:label for label,i in tag_to_ix.items()}\n",
        "\n",
        "# # ---------------------------\n",
        "# # Dataset class\n",
        "# # ---------------------------\n",
        "# # class NLPDataset(Dataset):\n",
        "# #     def __init__(self, hf_dataset):\n",
        "# #         self.data = hf_dataset\n",
        "\n",
        "# #     def __len__(self):\n",
        "# #         return len(self.data)\n",
        "\n",
        "# #     def __getitem__(self, idx):\n",
        "# #         tokens = self.data[idx][\"tokens\"]\n",
        "# #         token_ids = [vocab_stoi.get(t, vocab_stoi[\"<unk>\"]) for t in tokens]\n",
        "# #         tags_ids = self.data[idx][\"ner_tags\"]\n",
        "# #         return =token_ids, dtype=torch.long), torch.tensor(tags_ids, dtype=torch.long)\n",
        "# class NLPDataset(Dataset):\n",
        "#     def __init__(self, data, labeling_ner, vocab_stoi):\n",
        "#         self.data = data\n",
        "#         self.labeling_ner = labeling_ner\n",
        "#         self.vocab_stoi = vocab_stoi\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         # img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "#         tokens = self.data['tokens'][idx]\n",
        "#         token_ids = [self.vocab_stoi.get(w, self.vocab_stoi[\"<unk>\"]) for w in tokens]\n",
        "#         # token_ids = torch.tensor([self.word_to_ix[w] for w in tokens], dtype=torch.long)\n",
        "#         tags_ids = self.data[idx][\"ner_tags\"]\n",
        "#         return token_ids, tags_ids\n",
        "# # ---------------------------\n",
        "# # Collate function\n",
        "# # ---------------------------\n",
        "# from torch.nn.utils.rnn import pad_sequence\n",
        "# import torch\n",
        "\n",
        "# def collate_fn(batch):\n",
        "#     # batch: list of (tokens, tags)\n",
        "#     tokens_batch, tags_batch = zip(*batch)\n",
        "#     # tokens_batch = [[vocab_stoi.get(w, vocab_stoi[\"<unk>\"]) for w in seq] for seq in tokens_batch]\n",
        "#     tokens_batch = [torch.tensor(t) for t in tokens_batch]\n",
        "#     tags_batch = [torch.tensor(t) for t in tags_batch]\n",
        "\n",
        "#     # convert each sequence to tensor\n",
        "#     # tokens_batch_tensors = [torch.tensor(seq, dtype=torch.long) for seq in tokens_batch]\n",
        "#     # tags_batch_tensors   = [torch.tensor(seq, dtype=torch.long) for seq in tags_batch]\n",
        "\n",
        "#     # pad sequences to same length\n",
        "#     tokens_padded = pad_sequence(tokens_batch, batch_first=True, padding_value=0)\n",
        "#     tags_padded   = pad_sequence(tags_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "#     # create mask\n",
        "#     mask = tokens_padded != 0\n",
        "\n",
        "#     return tokens_padded, tags_padded, mask\n",
        "\n",
        "\n",
        "\n",
        "# # ---------------------------\n",
        "# # Create DataLoaders\n",
        "# # ---------------------------\n",
        "# loader_train = DataLoader(NLPDataset(dataset[\"train\"],labeling_ner, vocab_stoi), batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
        "# loader_val   = DataLoader(NLPDataset(dataset[\"validation\"],labeling_ner, vocab_stoi), batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
        "# loader_test  = DataLoader(NLPDataset(dataset[\"test\"],labeling_ner, vocab_stoi), batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# print(\"Vocabulary size:\", len(vocab_stoi))\n",
        "# print(\"Number of tags:\", len(tag_to_ix))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12daace5-3643-48f0-9004-ccc7b0cf133c",
      "metadata": {
        "id": "12daace5-3643-48f0-9004-ccc7b0cf133c"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader\n",
        "# # train_dataset = NLPDataset(dataset[\"train\"],labeling_ner, vocab_stoi)\n",
        "# # loader_train = DataLoader(train_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
        "# i = 0\n",
        "# # get first batch\n",
        "# for batch in loader_train:\n",
        "#     tokens_batch, tags_batch, mask = batch\n",
        "#     print(\"Tokens batch shape:\", tokens_batch)\n",
        "#     print(\"Tags batch shape  :\", tags_batch)\n",
        "#     print(\"Mask shape        :\", mask)\n",
        "#     if i == 3:\n",
        "#         break  # just take the first batch\n",
        "#     i +=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cae2073a-1471-4b22-b67d-f74986abef92",
      "metadata": {
        "id": "cae2073a-1471-4b22-b67d-f74986abef92"
      },
      "outputs": [],
      "source": [
        "# dataset[\"train\"][3][\"tokens\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "814832de-25d6-489b-8e72-65a57f228b9c",
      "metadata": {
        "id": "814832de-25d6-489b-8e72-65a57f228b9c"
      },
      "outputs": [],
      "source": [
        "# dataset[\"train\"][1]['ner_tags']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2f7acf0-7969-4429-9a0a-4e9a8afba5ed",
      "metadata": {
        "id": "f2f7acf0-7969-4429-9a0a-4e9a8afba5ed"
      },
      "outputs": [],
      "source": [
        "# dataset[\"train\"][\"ner_tags\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb00a006-b13c-4fdb-bdce-119d654238f8",
      "metadata": {
        "id": "eb00a006-b13c-4fdb-bdce-119d654238f8",
        "outputId": "e4d55186-4070-4316-b784-3fc2f5e9e064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Started\n",
            "Epoch 1, Batch 100: Processed 6400 tokens so far\n",
            "Epoch 1, Batch 200: Processed 12800 tokens so far\n",
            "Epoch 1, Batch 300: Processed 19200 tokens so far\n",
            "Epoch 1, Batch 400: Processed 25600 tokens so far\n",
            "Epoch 1, Batch 500: Processed 32000 tokens so far\n",
            "Epoch 1, Batch 600: Processed 38400 tokens so far\n",
            "Epoch 1, Batch 700: Processed 44800 tokens so far\n",
            "Epoch 1, Batch 800: Processed 51200 tokens so far\n",
            "Epoch 1, Batch 900: Processed 57600 tokens so far\n",
            "Epoch 1, Batch 1000: Processed 64000 tokens so far\n",
            "Epoch 1, Batch 1100: Processed 70400 tokens so far\n",
            "Epoch 1, Batch 1200: Processed 76800 tokens so far\n",
            "Epoch 1, Batch 1300: Processed 83200 tokens so far\n",
            "Epoch 1, Batch 1400: Processed 89600 tokens so far\n",
            "Epoch 1, Batch 1500: Processed 96000 tokens so far\n",
            "Epoch 1, Batch 1600: Processed 102400 tokens so far\n",
            "Epoch 1, Batch 1700: Processed 108800 tokens so far\n",
            "\n",
            "--- Epoch 1 Training Metrics ---\n",
            "Loss: 6.2975 | Token Acc: 0.8899 | F1 (filtered): 0.1654\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9910\n",
            "  Class 1: 0.2583\n",
            "  Class 2: 0.1897\n",
            "  Class 3: 0.0481\n",
            "  Class 4: 0.0511\n",
            "  Class 5: 0.0071\n",
            "  Class 6: 0.0106\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "Testing Epoch 1, Batch 100: Processed 6400 tokens so far\n",
            "Testing Epoch 1, Batch 200: Processed 12800 tokens so far\n",
            "Testing Epoch 1, Batch 300: Processed 19200 tokens so far\n",
            "Testing Epoch 1, Batch 400: Processed 25600 tokens so far\n",
            "\n",
            "--- Epoch 1 Testing Metrics ---\n",
            "Token Acc: 0.8897 | F1 (filtered): 0.1730\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9917\n",
            "  Class 1: 0.2708\n",
            "  Class 2: 0.1605\n",
            "  Class 3: 0.0805\n",
            "  Class 4: 0.0566\n",
            "  Class 5: 0.0212\n",
            "  Class 6: 0.0537\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "\n",
            "==================================================\n",
            "Training Started\n",
            "Epoch 2, Batch 100: Processed 6400 tokens so far\n",
            "Epoch 2, Batch 200: Processed 12800 tokens so far\n",
            "Epoch 2, Batch 300: Processed 19200 tokens so far\n",
            "Epoch 2, Batch 400: Processed 25600 tokens so far\n",
            "Epoch 2, Batch 500: Processed 32000 tokens so far\n",
            "Epoch 2, Batch 600: Processed 38400 tokens so far\n",
            "Epoch 2, Batch 700: Processed 44800 tokens so far\n",
            "Epoch 2, Batch 800: Processed 51200 tokens so far\n",
            "Epoch 2, Batch 900: Processed 57600 tokens so far\n",
            "Epoch 2, Batch 1000: Processed 64000 tokens so far\n",
            "Epoch 2, Batch 1100: Processed 70400 tokens so far\n",
            "Epoch 2, Batch 1200: Processed 76800 tokens so far\n",
            "Epoch 2, Batch 1300: Processed 83200 tokens so far\n",
            "Epoch 2, Batch 1400: Processed 89600 tokens so far\n",
            "Epoch 2, Batch 1500: Processed 96000 tokens so far\n",
            "Epoch 2, Batch 1600: Processed 102400 tokens so far\n",
            "Epoch 2, Batch 1700: Processed 108800 tokens so far\n",
            "\n",
            "--- Epoch 2 Training Metrics ---\n",
            "Loss: 5.6557 | Token Acc: 0.8949 | F1 (filtered): 0.2435\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9857\n",
            "  Class 1: 0.3488\n",
            "  Class 2: 0.2683\n",
            "  Class 3: 0.1413\n",
            "  Class 4: 0.1008\n",
            "  Class 5: 0.0408\n",
            "  Class 6: 0.0634\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "Testing Epoch 2, Batch 100: Processed 6400 tokens so far\n",
            "Testing Epoch 2, Batch 200: Processed 12800 tokens so far\n",
            "Testing Epoch 2, Batch 300: Processed 19200 tokens so far\n",
            "Testing Epoch 2, Batch 400: Processed 25600 tokens so far\n",
            "\n",
            "--- Epoch 2 Testing Metrics ---\n",
            "Token Acc: 0.8926 | F1 (filtered): 0.2316\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9867\n",
            "  Class 1: 0.3487\n",
            "  Class 2: 0.2391\n",
            "  Class 3: 0.1328\n",
            "  Class 4: 0.0822\n",
            "  Class 5: 0.0256\n",
            "  Class 6: 0.0318\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "\n",
            "==================================================\n",
            "Training Started\n",
            "Epoch 3, Batch 100: Processed 6400 tokens so far\n",
            "Epoch 3, Batch 200: Processed 12800 tokens so far\n",
            "Epoch 3, Batch 300: Processed 19200 tokens so far\n",
            "Epoch 3, Batch 400: Processed 25600 tokens so far\n",
            "Epoch 3, Batch 500: Processed 32000 tokens so far\n",
            "Epoch 3, Batch 600: Processed 38400 tokens so far\n",
            "Epoch 3, Batch 700: Processed 44800 tokens so far\n",
            "Epoch 3, Batch 800: Processed 51200 tokens so far\n",
            "Epoch 3, Batch 900: Processed 57600 tokens so far\n",
            "Epoch 3, Batch 1000: Processed 64000 tokens so far\n",
            "Epoch 3, Batch 1100: Processed 70400 tokens so far\n",
            "Epoch 3, Batch 1200: Processed 76800 tokens so far\n",
            "Epoch 3, Batch 1300: Processed 83200 tokens so far\n",
            "Epoch 3, Batch 1400: Processed 89600 tokens so far\n",
            "Epoch 3, Batch 1500: Processed 96000 tokens so far\n",
            "Epoch 3, Batch 1600: Processed 102400 tokens so far\n",
            "Epoch 3, Batch 1700: Processed 108800 tokens so far\n",
            "\n",
            "--- Epoch 3 Training Metrics ---\n",
            "Loss: 5.9831 | Token Acc: 0.8970 | F1 (filtered): 0.2701\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9845\n",
            "  Class 1: 0.3776\n",
            "  Class 2: 0.2889\n",
            "  Class 3: 0.1792\n",
            "  Class 4: 0.1227\n",
            "  Class 5: 0.0591\n",
            "  Class 6: 0.0865\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "Testing Epoch 3, Batch 100: Processed 6400 tokens so far\n",
            "Testing Epoch 3, Batch 200: Processed 12800 tokens so far\n",
            "Testing Epoch 3, Batch 300: Processed 19200 tokens so far\n",
            "Testing Epoch 3, Batch 400: Processed 25600 tokens so far\n",
            "\n",
            "--- Epoch 3 Testing Metrics ---\n",
            "Token Acc: 0.8909 | F1 (filtered): 0.2301\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9850\n",
            "  Class 1: 0.3344\n",
            "  Class 2: 0.2244\n",
            "  Class 3: 0.1901\n",
            "  Class 4: 0.1035\n",
            "  Class 5: 0.0242\n",
            "  Class 6: 0.0204\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "\n",
            "==================================================\n",
            "Training Started\n",
            "Epoch 4, Batch 100: Processed 6400 tokens so far\n",
            "Epoch 4, Batch 200: Processed 12800 tokens so far\n",
            "Epoch 4, Batch 300: Processed 19200 tokens so far\n",
            "Epoch 4, Batch 400: Processed 25600 tokens so far\n",
            "Epoch 4, Batch 500: Processed 32000 tokens so far\n",
            "Epoch 4, Batch 600: Processed 38400 tokens so far\n",
            "Epoch 4, Batch 700: Processed 44800 tokens so far\n",
            "Epoch 4, Batch 800: Processed 51200 tokens so far\n",
            "Epoch 4, Batch 900: Processed 57600 tokens so far\n",
            "Epoch 4, Batch 1000: Processed 64000 tokens so far\n",
            "Epoch 4, Batch 1100: Processed 70400 tokens so far\n",
            "Epoch 4, Batch 1200: Processed 76800 tokens so far\n",
            "Epoch 4, Batch 1300: Processed 83200 tokens so far\n",
            "Epoch 4, Batch 1400: Processed 89600 tokens so far\n",
            "Epoch 4, Batch 1500: Processed 96000 tokens so far\n",
            "Epoch 4, Batch 1600: Processed 102400 tokens so far\n",
            "Epoch 4, Batch 1700: Processed 108800 tokens so far\n",
            "\n",
            "--- Epoch 4 Training Metrics ---\n",
            "Loss: 5.2893 | Token Acc: 0.8973 | F1 (filtered): 0.2837\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9829\n",
            "  Class 1: 0.3830\n",
            "  Class 2: 0.2932\n",
            "  Class 3: 0.2008\n",
            "  Class 4: 0.1284\n",
            "  Class 5: 0.1054\n",
            "  Class 6: 0.1230\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "Testing Epoch 4, Batch 100: Processed 6400 tokens so far\n",
            "Testing Epoch 4, Batch 200: Processed 12800 tokens so far\n",
            "Testing Epoch 4, Batch 300: Processed 19200 tokens so far\n",
            "Testing Epoch 4, Batch 400: Processed 25600 tokens so far\n",
            "\n",
            "--- Epoch 4 Testing Metrics ---\n",
            "Token Acc: 0.8894 | F1 (filtered): 0.2779\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9765\n",
            "  Class 1: 0.3510\n",
            "  Class 2: 0.3503\n",
            "  Class 3: 0.1534\n",
            "  Class 4: 0.0941\n",
            "  Class 5: 0.1831\n",
            "  Class 6: 0.0516\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "\n",
            "==================================================\n",
            "Training Started\n",
            "Epoch 5, Batch 100: Processed 6400 tokens so far\n",
            "Epoch 5, Batch 200: Processed 12800 tokens so far\n",
            "Epoch 5, Batch 300: Processed 19200 tokens so far\n",
            "Epoch 5, Batch 400: Processed 25600 tokens so far\n",
            "Epoch 5, Batch 500: Processed 32000 tokens so far\n",
            "Epoch 5, Batch 600: Processed 38400 tokens so far\n",
            "Epoch 5, Batch 700: Processed 44800 tokens so far\n",
            "Epoch 5, Batch 800: Processed 51200 tokens so far\n",
            "Epoch 5, Batch 900: Processed 57600 tokens so far\n",
            "Epoch 5, Batch 1000: Processed 64000 tokens so far\n",
            "Epoch 5, Batch 1100: Processed 70400 tokens so far\n",
            "Epoch 5, Batch 1200: Processed 76800 tokens so far\n",
            "Epoch 5, Batch 1300: Processed 83200 tokens so far\n",
            "Epoch 5, Batch 1400: Processed 89600 tokens so far\n",
            "Epoch 5, Batch 1500: Processed 96000 tokens so far\n",
            "Epoch 5, Batch 1600: Processed 102400 tokens so far\n",
            "Epoch 5, Batch 1700: Processed 108800 tokens so far\n",
            "\n",
            "--- Epoch 5 Training Metrics ---\n",
            "Loss: 5.5500 | Token Acc: 0.8974 | F1 (filtered): 0.2977\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9811\n",
            "  Class 1: 0.3795\n",
            "  Class 2: 0.3013\n",
            "  Class 3: 0.2177\n",
            "  Class 4: 0.1428\n",
            "  Class 5: 0.1806\n",
            "  Class 6: 0.1720\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "Testing Epoch 5, Batch 100: Processed 6400 tokens so far\n",
            "Testing Epoch 5, Batch 200: Processed 12800 tokens so far\n",
            "Testing Epoch 5, Batch 300: Processed 19200 tokens so far\n",
            "Testing Epoch 5, Batch 400: Processed 25600 tokens so far\n",
            "\n",
            "--- Epoch 5 Testing Metrics ---\n",
            "Token Acc: 0.8879 | F1 (filtered): 0.2681\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9760\n",
            "  Class 1: 0.3513\n",
            "  Class 2: 0.2572\n",
            "  Class 3: 0.1755\n",
            "  Class 4: 0.1297\n",
            "  Class 5: 0.1943\n",
            "  Class 6: 0.1080\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "\n",
            "==================================================\n",
            "Training Started\n",
            "Epoch 6, Batch 100: Processed 6400 tokens so far\n",
            "Epoch 6, Batch 200: Processed 12800 tokens so far\n",
            "Epoch 6, Batch 300: Processed 19200 tokens so far\n",
            "Epoch 6, Batch 400: Processed 25600 tokens so far\n",
            "Epoch 6, Batch 500: Processed 32000 tokens so far\n",
            "Epoch 6, Batch 600: Processed 38400 tokens so far\n",
            "Epoch 6, Batch 700: Processed 44800 tokens so far\n",
            "Epoch 6, Batch 800: Processed 51200 tokens so far\n",
            "Epoch 6, Batch 900: Processed 57600 tokens so far\n",
            "Epoch 6, Batch 1000: Processed 64000 tokens so far\n",
            "Epoch 6, Batch 1100: Processed 70400 tokens so far\n",
            "Epoch 6, Batch 1200: Processed 76800 tokens so far\n",
            "Epoch 6, Batch 1300: Processed 83200 tokens so far\n",
            "Epoch 6, Batch 1400: Processed 89600 tokens so far\n",
            "Epoch 6, Batch 1500: Processed 96000 tokens so far\n",
            "Epoch 6, Batch 1600: Processed 102400 tokens so far\n",
            "Epoch 6, Batch 1700: Processed 108800 tokens so far\n",
            "\n",
            "--- Epoch 6 Training Metrics ---\n",
            "Loss: 4.8577 | Token Acc: 0.8970 | F1 (filtered): 0.3008\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9802\n",
            "  Class 1: 0.3752\n",
            "  Class 2: 0.2959\n",
            "  Class 3: 0.2257\n",
            "  Class 4: 0.1474\n",
            "  Class 5: 0.2111\n",
            "  Class 6: 0.1985\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "Testing Epoch 6, Batch 100: Processed 6400 tokens so far\n",
            "Testing Epoch 6, Batch 200: Processed 12800 tokens so far\n",
            "Testing Epoch 6, Batch 300: Processed 19200 tokens so far\n",
            "Testing Epoch 6, Batch 400: Processed 25600 tokens so far\n",
            "\n",
            "--- Epoch 6 Testing Metrics ---\n",
            "Token Acc: 0.8882 | F1 (filtered): 0.2636\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9771\n",
            "  Class 1: 0.3438\n",
            "  Class 2: 0.2535\n",
            "  Class 3: 0.1550\n",
            "  Class 4: 0.0968\n",
            "  Class 5: 0.2002\n",
            "  Class 6: 0.1782\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "\n",
            "==================================================\n",
            "Training Started\n",
            "Epoch 7, Batch 100: Processed 6400 tokens so far\n",
            "Epoch 7, Batch 200: Processed 12800 tokens so far\n",
            "Epoch 7, Batch 300: Processed 19200 tokens so far\n",
            "Epoch 7, Batch 400: Processed 25600 tokens so far\n",
            "Epoch 7, Batch 500: Processed 32000 tokens so far\n",
            "Epoch 7, Batch 600: Processed 38400 tokens so far\n",
            "Epoch 7, Batch 700: Processed 44800 tokens so far\n",
            "Epoch 7, Batch 800: Processed 51200 tokens so far\n",
            "Epoch 7, Batch 900: Processed 57600 tokens so far\n",
            "Epoch 7, Batch 1000: Processed 64000 tokens so far\n",
            "Epoch 7, Batch 1100: Processed 70400 tokens so far\n",
            "Epoch 7, Batch 1200: Processed 76800 tokens so far\n",
            "Epoch 7, Batch 1300: Processed 83200 tokens so far\n",
            "Epoch 7, Batch 1400: Processed 89600 tokens so far\n",
            "Epoch 7, Batch 1500: Processed 96000 tokens so far\n",
            "Epoch 7, Batch 1600: Processed 102400 tokens so far\n",
            "Epoch 7, Batch 1700: Processed 108800 tokens so far\n",
            "\n",
            "--- Epoch 7 Training Metrics ---\n",
            "Loss: 4.9445 | Token Acc: 0.8971 | F1 (filtered): 0.3056\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9797\n",
            "  Class 1: 0.3748\n",
            "  Class 2: 0.2922\n",
            "  Class 3: 0.2330\n",
            "  Class 4: 0.1542\n",
            "  Class 5: 0.2394\n",
            "  Class 6: 0.2213\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "Testing Epoch 7, Batch 100: Processed 6400 tokens so far\n",
            "Testing Epoch 7, Batch 200: Processed 12800 tokens so far\n",
            "Testing Epoch 7, Batch 300: Processed 19200 tokens so far\n",
            "Testing Epoch 7, Batch 400: Processed 25600 tokens so far\n",
            "\n",
            "--- Epoch 7 Testing Metrics ---\n",
            "Token Acc: 0.8789 | F1 (filtered): 0.2824\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9638\n",
            "  Class 1: 0.3560\n",
            "  Class 2: 0.2423\n",
            "  Class 3: 0.1634\n",
            "  Class 4: 0.1049\n",
            "  Class 5: 0.2600\n",
            "  Class 6: 0.3251\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "\n",
            "==================================================\n",
            "Training Started\n",
            "Epoch 8, Batch 100: Processed 6400 tokens so far\n",
            "Epoch 8, Batch 200: Processed 12800 tokens so far\n",
            "Epoch 8, Batch 300: Processed 19200 tokens so far\n",
            "Epoch 8, Batch 400: Processed 25600 tokens so far\n",
            "Epoch 8, Batch 500: Processed 32000 tokens so far\n",
            "Epoch 8, Batch 600: Processed 38400 tokens so far\n",
            "Epoch 8, Batch 700: Processed 44800 tokens so far\n",
            "Epoch 8, Batch 800: Processed 51200 tokens so far\n",
            "Epoch 8, Batch 900: Processed 57600 tokens so far\n",
            "Epoch 8, Batch 1000: Processed 64000 tokens so far\n",
            "Epoch 8, Batch 1100: Processed 70400 tokens so far\n",
            "Epoch 8, Batch 1200: Processed 76800 tokens so far\n",
            "Epoch 8, Batch 1300: Processed 83200 tokens so far\n",
            "Epoch 8, Batch 1400: Processed 89600 tokens so far\n",
            "Epoch 8, Batch 1500: Processed 96000 tokens so far\n",
            "Epoch 8, Batch 1600: Processed 102400 tokens so far\n",
            "Epoch 8, Batch 1700: Processed 108800 tokens so far\n",
            "\n",
            "--- Epoch 8 Training Metrics ---\n",
            "Loss: 4.8241 | Token Acc: 0.8971 | F1 (filtered): 0.3085\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9792\n",
            "  Class 1: 0.3721\n",
            "  Class 2: 0.2899\n",
            "  Class 3: 0.2411\n",
            "  Class 4: 0.1584\n",
            "  Class 5: 0.2565\n",
            "  Class 6: 0.2492\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "Testing Epoch 8, Batch 100: Processed 6400 tokens so far\n",
            "Testing Epoch 8, Batch 200: Processed 12800 tokens so far\n",
            "Testing Epoch 8, Batch 300: Processed 19200 tokens so far\n",
            "Testing Epoch 8, Batch 400: Processed 25600 tokens so far\n",
            "\n",
            "--- Epoch 8 Testing Metrics ---\n",
            "Token Acc: 0.8907 | F1 (filtered): 0.2901\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9761\n",
            "  Class 1: 0.3873\n",
            "  Class 2: 0.3415\n",
            "  Class 3: 0.1502\n",
            "  Class 4: 0.1051\n",
            "  Class 5: 0.1675\n",
            "  Class 6: 0.0360\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "\n",
            "==================================================\n",
            "Training Started\n",
            "Epoch 9, Batch 100: Processed 6400 tokens so far\n",
            "Epoch 9, Batch 200: Processed 12800 tokens so far\n",
            "Epoch 9, Batch 300: Processed 19200 tokens so far\n",
            "Epoch 9, Batch 400: Processed 25600 tokens so far\n",
            "Epoch 9, Batch 500: Processed 32000 tokens so far\n",
            "Epoch 9, Batch 600: Processed 38400 tokens so far\n",
            "Epoch 9, Batch 700: Processed 44800 tokens so far\n",
            "Epoch 9, Batch 800: Processed 51200 tokens so far\n",
            "Epoch 9, Batch 900: Processed 57600 tokens so far\n",
            "Epoch 9, Batch 1000: Processed 64000 tokens so far\n",
            "Epoch 9, Batch 1100: Processed 70400 tokens so far\n",
            "Epoch 9, Batch 1200: Processed 76800 tokens so far\n",
            "Epoch 9, Batch 1300: Processed 83200 tokens so far\n",
            "Epoch 9, Batch 1400: Processed 89600 tokens so far\n",
            "Epoch 9, Batch 1500: Processed 96000 tokens so far\n",
            "Epoch 9, Batch 1600: Processed 102400 tokens so far\n",
            "Epoch 9, Batch 1700: Processed 108800 tokens so far\n",
            "\n",
            "--- Epoch 9 Training Metrics ---\n",
            "Loss: 3.7512 | Token Acc: 0.8974 | F1 (filtered): 0.3112\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9792\n",
            "  Class 1: 0.3749\n",
            "  Class 2: 0.2891\n",
            "  Class 3: 0.2468\n",
            "  Class 4: 0.1632\n",
            "  Class 5: 0.2605\n",
            "  Class 6: 0.2506\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "Testing Epoch 9, Batch 100: Processed 6400 tokens so far\n",
            "Testing Epoch 9, Batch 200: Processed 12800 tokens so far\n",
            "Testing Epoch 9, Batch 300: Processed 19200 tokens so far\n",
            "Testing Epoch 9, Batch 400: Processed 25600 tokens so far\n",
            "\n",
            "--- Epoch 9 Testing Metrics ---\n",
            "Token Acc: 0.8810 | F1 (filtered): 0.2876\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9655\n",
            "  Class 1: 0.3565\n",
            "  Class 2: 0.2950\n",
            "  Class 3: 0.1809\n",
            "  Class 4: 0.1124\n",
            "  Class 5: 0.2337\n",
            "  Class 6: 0.2175\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "\n",
            "==================================================\n",
            "Training Started\n",
            "Epoch 10, Batch 100: Processed 6400 tokens so far\n",
            "Epoch 10, Batch 200: Processed 12800 tokens so far\n",
            "Epoch 10, Batch 300: Processed 19200 tokens so far\n",
            "Epoch 10, Batch 400: Processed 25600 tokens so far\n",
            "Epoch 10, Batch 500: Processed 32000 tokens so far\n",
            "Epoch 10, Batch 600: Processed 38400 tokens so far\n",
            "Epoch 10, Batch 700: Processed 44800 tokens so far\n",
            "Epoch 10, Batch 800: Processed 51200 tokens so far\n",
            "Epoch 10, Batch 900: Processed 57600 tokens so far\n",
            "Epoch 10, Batch 1000: Processed 64000 tokens so far\n",
            "Epoch 10, Batch 1100: Processed 70400 tokens so far\n",
            "Epoch 10, Batch 1200: Processed 76800 tokens so far\n",
            "Epoch 10, Batch 1300: Processed 83200 tokens so far\n",
            "Epoch 10, Batch 1400: Processed 89600 tokens so far\n",
            "Epoch 10, Batch 1500: Processed 96000 tokens so far\n",
            "Epoch 10, Batch 1600: Processed 102400 tokens so far\n",
            "Epoch 10, Batch 1700: Processed 108800 tokens so far\n",
            "\n",
            "--- Epoch 10 Training Metrics ---\n",
            "Loss: 5.5836 | Token Acc: 0.8969 | F1 (filtered): 0.3104\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9787\n",
            "  Class 1: 0.3735\n",
            "  Class 2: 0.2814\n",
            "  Class 3: 0.2458\n",
            "  Class 4: 0.1664\n",
            "  Class 5: 0.2687\n",
            "  Class 6: 0.2608\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "Testing Epoch 10, Batch 100: Processed 6400 tokens so far\n",
            "Testing Epoch 10, Batch 200: Processed 12800 tokens so far\n",
            "Testing Epoch 10, Batch 300: Processed 19200 tokens so far\n",
            "Testing Epoch 10, Batch 400: Processed 25600 tokens so far\n",
            "\n",
            "--- Epoch 10 Testing Metrics ---\n",
            "Token Acc: 0.8789 | F1 (filtered): 0.3045\n",
            "Per-class Accuracy:\n",
            "  Class 0: 0.9606\n",
            "  Class 1: 0.3709\n",
            "  Class 2: 0.3459\n",
            "  Class 3: 0.1763\n",
            "  Class 4: 0.1270\n",
            "  Class 5: 0.2252\n",
            "  Class 6: 0.2412\n",
            "  Class 7: N/A\n",
            "  Class 8: N/A\n",
            "\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import torch\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "num_classes = 9  # total tags\n",
        "o_class = 0      # majority \"O\" class\n",
        "class_names = [f\"Class {i}\" for i in range(num_classes)]\n",
        "\n",
        "class_weights = torch.tensor([0.00000000000000000000000000000001] + [1.0]*(num_classes-1), dtype=torch.float)\n",
        "print_every = 100  # print progress every 100 batches\n",
        "\n",
        "for epoch in range(10):\n",
        "    print(f'Training Started')\n",
        "    # ---------------------------\n",
        "    # Training\n",
        "    # ---------------------------\n",
        "    all_true_train = []\n",
        "    all_pred_train = []\n",
        "\n",
        "    for batch_idx, batch in enumerate(loader_train, 1):\n",
        "        tokens_batch, tags_batch, mask = batch\n",
        "        mask[:, 0] = True\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(tokens_batch, tags_batch, mask)\n",
        "        #* class_weights[tags_batch].mean()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = model(tokens_batch, mask=mask)\n",
        "            batch_size = tokens_batch.size(0)\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                seq_len_i = mask[i].sum().item()\n",
        "                true_tags = tags_batch[i, :seq_len_i].tolist()\n",
        "                pred_tags = preds[i][:seq_len_i]\n",
        "                all_true_train.extend(true_tags)\n",
        "                all_pred_train.extend(pred_tags)\n",
        "\n",
        "        if batch_idx % print_every == 0:\n",
        "            print(f\"Epoch {epoch+1}, Batch {batch_idx}: Processed {batch_idx * batch_size} tokens so far\")\n",
        "\n",
        "    # Filter out O-class for F1\n",
        "    filtered_idx = [i for i, t in enumerate(all_true_train) if t != o_class]\n",
        "    filtered_true = [all_true_train[i] for i in filtered_idx]\n",
        "    filtered_pred = [all_pred_train[i] for i in filtered_idx]\n",
        "\n",
        "    train_f1_filtered = f1_score(filtered_true, filtered_pred, average='micro') if filtered_true else 0.0\n",
        "    train_acc = accuracy_score(all_true_train, all_pred_train)\n",
        "\n",
        "    per_class_acc = []\n",
        "    for c in range(num_classes):\n",
        "        idx = [i for i, t in enumerate(all_true_train) if t == c]\n",
        "        if len(idx) == 0:\n",
        "            per_class_acc.append(None)\n",
        "        else:\n",
        "            per_class_acc.append(sum(all_pred_train[i] == all_true_train[i] for i in idx) / len(idx))\n",
        "\n",
        "    print(f\"\\n--- Epoch {epoch+1} Training Metrics ---\")\n",
        "    print(f\"Loss: {loss.item():.4f} | Token Acc: {train_acc:.4f} | F1 (filtered): {train_f1_filtered:.4f}\")\n",
        "    print(\"Per-class Accuracy:\")\n",
        "    for c, acc in zip(class_names, per_class_acc):\n",
        "        print(f\"  {c}: {acc:.4f}\" if acc is not None else f\"  {c}: N/A\")\n",
        "\n",
        "    # ---------------------------\n",
        "    # Testing\n",
        "    # ---------------------------\n",
        "    all_true_test = []\n",
        "    all_pred_test = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(loader_test, 1):\n",
        "            tokens_batch, tags_batch, mask = batch\n",
        "            mask[:, 0] = True\n",
        "\n",
        "            preds = model(tokens_batch, mask=mask)\n",
        "            batch_size = tokens_batch.size(0)\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                seq_len_i = mask[i].sum().item()\n",
        "                true_tags = tags_batch[i, :seq_len_i].tolist()\n",
        "                pred_tags = preds[i][:seq_len_i]\n",
        "                all_true_test.extend(true_tags)\n",
        "                all_pred_test.extend(pred_tags)\n",
        "\n",
        "            if batch_idx % print_every == 0:\n",
        "                print(f\"Testing Epoch {epoch+1}, Batch {batch_idx}: Processed {batch_idx * batch_size} tokens so far\")\n",
        "\n",
        "    filtered_idx_test = [i for i, t in enumerate(all_true_test) if t != o_class]\n",
        "    filtered_true_test = [all_true_test[i] for i in filtered_idx_test]\n",
        "    filtered_pred_test = [all_pred_test[i] for i in filtered_idx_test]\n",
        "\n",
        "    test_f1_filtered = f1_score(filtered_true_test, filtered_pred_test, average='micro') if filtered_true_test else 0.0\n",
        "    test_acc = accuracy_score(all_true_test, all_pred_test)\n",
        "\n",
        "    per_class_acc_test = []\n",
        "    for c in range(num_classes):\n",
        "        idx = [i for i, t in enumerate(all_true_test) if t == c]\n",
        "        if len(idx) == 0:\n",
        "            per_class_acc_test.append(None)\n",
        "        else:\n",
        "            per_class_acc_test.append(sum(all_pred_test[i] == all_true_test[i] for i in idx) / len(idx))\n",
        "\n",
        "    print(f\"\\n--- Epoch {epoch+1} Testing Metrics ---\")\n",
        "    print(f\"Token Acc: {test_acc:.4f} | F1 (filtered): {test_f1_filtered:.4f}\")\n",
        "    print(\"Per-class Accuracy:\")\n",
        "    for c, acc in zip(class_names, per_class_acc_test):\n",
        "        print(f\"  {c}: {acc:.4f}\" if acc is not None else f\"  {c}: N/A\")\n",
        "    print(\"\\n\" + \"=\"*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b30b22fd-7fa6-4942-91d0-b24beff4f07c",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "b30b22fd-7fa6-4942-91d0-b24beff4f07c"
      },
      "outputs": [],
      "source": [
        "tag_to_ix = {\n",
        "    \"O\": 0,\n",
        "    \"B-POS\": 1,\n",
        "    \"I-POS\": 2,\n",
        "    \"B-NEG\": 3,\n",
        "    \"I-NEG\": 4,\n",
        "    \"B-NEU\": 5,\n",
        "    \"I-NEU\": 6\n",
        "}\n",
        "ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56dd790b-3ba8-47b5-8cde-29a030eb4038",
      "metadata": {
        "id": "56dd790b-3ba8-47b5-8cde-29a030eb4038",
        "outputId": "fd2baebe-df6b-4846-ff3b-ceef9a296e7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "musik B-POS\n",
            "bagus I-POS\n",
            "banget B-POS\n",
            "aku O\n",
            "sampai O\n",
            "nangis. B-POS\n"
          ]
        }
      ],
      "source": [
        "text = \"musik bagus banget aku sampai nangis.\"\n",
        "tokens = text.split()  # simple tokenization, or use your tokenizer\n",
        "token_ids = [vocab_stoi.get(t, vocab_stoi[\"<unk>\"]) for t in tokens]\n",
        "tokens_tensor = torch.tensor(token_ids).unsqueeze(0)  # add batch dimension\n",
        "mask = torch.ones(tokens_tensor.shape, dtype=torch.bool)  # all real tokens\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred_tags = model(tokens_tensor, mask=mask)  # returns list of tag indices\n",
        "pred_labels = [ix_to_tag[idx] for idx in pred_tags[0]]  # pred_tags[0] because batch_size=1\n",
        "for token, label in zip(tokens, pred_labels):\n",
        "    print(token, label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33035e17-d90f-4f62-9991-8cc906442b8b",
      "metadata": {
        "id": "33035e17-d90f-4f62-9991-8cc906442b8b",
        "outputId": "4d26d10f-71ce-43e9-a45c-5ad9836a3080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1, 2], [2, 3], [2, 4], [4, 5]]\n"
          ]
        }
      ],
      "source": [
        "b = [[1,2],[2,3]]\n",
        "a = [[2,4], [4,5]]\n",
        "\n",
        "b.extend(a)  # adds each sublist of a to b\n",
        "print(b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bced3351-be4d-4d17-aa30-bb6da3a80277",
      "metadata": {
        "id": "bced3351-be4d-4d17-aa30-bb6da3a80277",
        "outputId": "29ecfb78-847c-45ed-bba7-1d5f019e577f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 298,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = [[0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
        "f1_score(a, a, average='micro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a0f2374-43f2-4093-b7a2-519429713f25",
      "metadata": {
        "id": "6a0f2374-43f2-4093-b7a2-519429713f25"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "\n",
        "# # suppose encoded is [seq_len, batch_size] = [5, 3]\n",
        "# # seq_len, batch_size = 5, 3\n",
        "# # encoded = torch.randint(0, 10, (seq_len, batch_size))\n",
        "\n",
        "# # random mask (True/False) but first token always True\n",
        "# mask = torch.randint(0, 2, (seq_len, batch_size), dtype=torch.bool)\n",
        "# mask[0, :] = True  # first timestep must be True for CRF\n",
        "\n",
        "# print(\"Encoded:\\n\", encoded)\n",
        "# print(\"Random mask:\\n\", mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1699aea4-d71f-4155-9b42-1135c92ccc46",
      "metadata": {
        "id": "1699aea4-d71f-4155-9b42-1135c92ccc46"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "\n",
        "# # vocab\n",
        "# vocab_stoi = {\n",
        "#     \"<pad>\": 0,\n",
        "#     \"<unk>\": 1,\n",
        "#     \"John\": 2,\n",
        "#     \"lives\": 3,\n",
        "#     \"in\": 4,\n",
        "#     \"New\": 5,\n",
        "#     \"York\": 6\n",
        "# }\n",
        "\n",
        "# # sentences (last two sentences have 0 to indicate padding)\n",
        "# sentence = [\n",
        "#     [\"John\", \"lives\", \"in\", \"New\", \"York\", \"<pad>\"],\n",
        "#     [\"John\", \"lives\", \"in\", \"York\", \"New\", \"lives\"],\n",
        "#     [\"lives\", \"lives\", \"in\", \"New\", \"York\", \"<pad>\"]\n",
        "# ]\n",
        "\n",
        "# # encode\n",
        "# encoded = [\n",
        "#     [vocab_stoi[w] if w in vocab_stoi else vocab_stoi[\"<unk>\"] for w in sent]\n",
        "#     for sent in sentence\n",
        "# ]\n",
        "# encoded = torch.tensor(encoded)  # shape: [batch_size, seq_len]\n",
        "# print(\"Encoded:\\n\", encoded)\n",
        "\n",
        "# # ---------------------------\n",
        "# # make tags\n",
        "# # ---------------------------\n",
        "# tag_to_ix = {\"B-PER\":0, \"I-PER\":1, \"B-LOC\":2, \"I-LOC\":3, \"O\":4}\n",
        "\n",
        "# # tags for non-padding tokens\n",
        "# tags = [\n",
        "#     [tag_to_ix[\"B-PER\"], tag_to_ix[\"O\"], tag_to_ix[\"O\"], tag_to_ix[\"B-LOC\"], tag_to_ix[\"I-LOC\"], tag_to_ix[\"O\"]],\n",
        "#     [tag_to_ix[\"B-PER\"], tag_to_ix[\"O\"], tag_to_ix[\"O\"], tag_to_ix[\"B-LOC\"], tag_to_ix[\"I-LOC\"], tag_to_ix[\"O\"]],\n",
        "#     [tag_to_ix[\"O\"], tag_to_ix[\"O\"], tag_to_ix[\"O\"], tag_to_ix[\"B-LOC\"], tag_to_ix[\"I-LOC\"], tag_to_ix[\"O\"]]\n",
        "# ]\n",
        "# tags = torch.tensor(tags)  # shape: [batch_size, seq_len]\n",
        "\n",
        "# # ---------------------------\n",
        "# # make mask: True for real tokens, False for padding\n",
        "# mask = encoded != vocab_stoi[\"<pad>\"]\n",
        "# mask[0] = True\n",
        "# print(\"Tags:\\n\", tags)\n",
        "# print(\"Mask:\\n\", mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3af100b-a191-4b5c-8ecf-04bbb693b38f",
      "metadata": {
        "id": "f3af100b-a191-4b5c-8ecf-04bbb693b38f",
        "outputId": "83385563-1a69-4696-cacd-e7877c1e9fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([True, True, True, True, True, True])\n"
          ]
        }
      ],
      "source": [
        "print(mask[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca1d6eda-4ade-40f6-9586-29d9adfaf6a0",
      "metadata": {
        "id": "ca1d6eda-4ade-40f6-9586-29d9adfaf6a0"
      },
      "outputs": [],
      "source": [
        "# for i in range(20):\n",
        "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "#     model = LSTM_CRF()\n",
        "#     loss = model.loss(encoded, tags, mask)\n",
        "#     print(loss)\n",
        "#     loss.backward()\n",
        "#     optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e171b87-d3ca-492d-8beb-108359239d23",
      "metadata": {
        "id": "1e171b87-d3ca-492d-8beb-108359239d23",
        "outputId": "5ca37652-5558-43a3-ab95-fb54943163e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch-crf\n",
            "  Downloading pytorch_crf-0.7.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~umpy (D:\\anaconda3\\envs\\capstone\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~upyter-core (D:\\anaconda3\\envs\\capstone\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (D:\\anaconda3\\envs\\capstone\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~upyter-core (D:\\anaconda3\\envs\\capstone\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (D:\\anaconda3\\envs\\capstone\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~upyter-core (D:\\anaconda3\\envs\\capstone\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install pytorch-crf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a083d86-9c00-406c-9901-3df1caad95f5",
      "metadata": {
        "id": "6a083d86-9c00-406c-9901-3df1caad95f5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchcrf import CRF\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# ---------------------------\n",
        "# Dummy dataset\n",
        "# ---------------------------\n",
        "data = [\n",
        "    {\"tokens\": [\"John\", \"lives\", \"in\", \"New\", \"York\"], \"tags\": [\"B-PER\", \"O\", \"O\", \"B-LOC\", \"I-LOC\"]},\n",
        "    {\"tokens\": [\"Mary\", \"works\", \"at\", \"Google\"], \"tags\": [\"B-PER\", \"O\", \"O\", \"B-ORG\"]}\n",
        "]\n",
        "\n",
        "# Build vocab and tag2idx\n",
        "word_to_ix = {}\n",
        "for sent in data:\n",
        "    for word in sent[\"tokens\"]:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "tag_to_ix = {\"B-PER\":0, \"I-PER\":1, \"B-LOC\":2, \"I-LOC\":3, \"B-ORG\":4, \"I-ORG\":5, \"O\":6}\n",
        "\n",
        "# ---------------------------\n",
        "# Dataset class\n",
        "# ---------------------------\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, data, word_to_ix, tag_to_ix):\n",
        "        self.data = data\n",
        "        self.word_to_ix = word_to_ix\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.data[idx][\"tokens\"]\n",
        "        tags = self.data[idx][\"tags\"]\n",
        "        token_ids = torch.tensor([self.word_to_ix[w] for w in tokens], dtype=torch.long)\n",
        "        tag_ids = torch.tensor([self.tag_to_ix[t] for t in tags], dtype=torch.long)\n",
        "        return token_ids, tag_ids\n",
        "\n",
        "dataset = NERDataset(data, word_to_ix, tag_to_ix)\n",
        "loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=lambda x: x)\n",
        "\n",
        "# ---------------------------\n",
        "# Simple LSTM + CRF model\n",
        "# ---------------------------\n",
        "\n",
        "# ---------------------------\n",
        "# Training loop\n",
        "# ---------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4006160-aee3-43e8-b594-8b444b6235ae",
      "metadata": {
        "id": "d4006160-aee3-43e8-b594-8b444b6235ae",
        "outputId": "816ccd10-df18-4c71-b93c-db546054a443"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['John', 'lives', 'in', 'New', 'York']"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[0]['tokens']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f693c08-6d28-4bbd-8f5b-6373473c321b",
      "metadata": {
        "id": "0f693c08-6d28-4bbd-8f5b-6373473c321b",
        "outputId": "6dec3e82-f113-491a-d470-36b980355fe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens padded:\n",
            " tensor([[0, 1, 2, 3, 4],\n",
            "        [5, 6, 7, 8, 0]])\n",
            "Tags padded:\n",
            " tensor([[0, 6, 6, 2, 3],\n",
            "        [0, 6, 6, 4, 0]])\n",
            "Mask:\n",
            " tensor([[ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True, False]])\n"
          ]
        }
      ],
      "source": [
        "# get one batch from your loader\n",
        "batch = next(iter(loader))  # grabs the first batch\n",
        "tokens_batch, tags_batch = zip(*batch)\n",
        "\n",
        "# pad sequences to max length in batch\n",
        "max_len = max(len(t) for t in tokens_batch)\n",
        "batch_size = len(batch)\n",
        "\n",
        "tokens_padded = torch.zeros(batch_size, max_len, dtype=torch.long)\n",
        "tags_padded = torch.zeros(batch_size, max_len, dtype=torch.long)\n",
        "mask = torch.zeros(batch_size, max_len, dtype=torch.bool)\n",
        "\n",
        "for i, (t, y) in enumerate(zip(tokens_batch, tags_batch)):\n",
        "    tokens_padded[i, :len(t)] = t\n",
        "    tags_padded[i, :len(y)] = y\n",
        "    mask[i, :len(t)] = 1\n",
        "\n",
        "# ensure first timestep is True for CRF\n",
        "mask[0] = True\n",
        "\n",
        "print(\"Tokens padded:\\n\", tokens_padded)\n",
        "print(\"Tags padded:\\n\", tags_padded)\n",
        "print(\"Mask:\\n\", mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ae3b48c-eec1-45af-b842-2f0a015c7959",
      "metadata": {
        "id": "2ae3b48c-eec1-45af-b842-2f0a015c7959"
      },
      "outputs": [],
      "source": [
        "for i in range(20):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    model = LSTM_CRF()\n",
        "    loss = model.loss(tokens_padded, tags_padded, mask)\n",
        "    print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ade80732-84ca-425e-a0ed-23d489303c0e",
      "metadata": {
        "id": "ade80732-84ca-425e-a0ed-23d489303c0e"
      },
      "outputs": [],
      "source": [
        "import numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2947930a-2c77-44f1-b1f2-5b815ea7ded7",
      "metadata": {
        "scrolled": true,
        "id": "2947930a-2c77-44f1-b1f2-5b815ea7ded7",
        "outputId": "37141e40-aa5e-45e7-99c3-880adaf7b584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenCV bindings requires \"numpy\" package.\n",
            "Install it via command:\n",
            "    pip install numpy\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.models.bert.modeling_bert because of the following error (look up to see its traceback):\nNo module named 'numpy.core.multiarray'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mD:\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1863\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   1862\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1863\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1864\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mD:\\anaconda3\\envs\\capstone\\Lib\\importlib\\__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1204\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1147\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:690\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:940\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:241\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mD:\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:47\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling_outputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     37\u001b[39m     BaseModelOutputWithPastAndCrossAttentions,\n\u001b[32m     38\u001b[39m     BaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     TokenClassifierOutput,\n\u001b[32m     46\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpytorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n",
            "\u001b[36mFile \u001b[39m\u001b[32mD:\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\modeling_utils.py:53\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msdpa_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sdpa_attention_forward\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloss\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloss_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LOSS_MAPPING\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpytorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     55\u001b[39m     Conv1D,\n\u001b[32m     56\u001b[39m     apply_chunking_to_forward,\n\u001b[32m   (...)\u001b[39m\u001b[32m     62\u001b[39m     translate_to_torch_parallel_style,\n\u001b[32m     63\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mD:\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\loss\\loss_utils.py:19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BCEWithLogitsLoss, MSELoss\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloss_deformable_detr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloss_for_object_detection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ForObjectDetectionLoss, ForSegmentationLoss\n",
            "\u001b[36mFile \u001b[39m\u001b[32mD:\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\loss\\loss_deformable_detr.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_transforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m center_to_corners_format\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_scipy_available\n",
            "\u001b[36mFile \u001b[39m\u001b[32mD:\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\image_transforms.py:22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     23\u001b[39m     ChannelDimension,\n\u001b[32m     24\u001b[39m     ImageInput,\n\u001b[32m     25\u001b[39m     get_channel_dimension_axis,\n\u001b[32m     26\u001b[39m     get_image_size,\n\u001b[32m     27\u001b[39m     infer_channel_dimension_format,\n\u001b[32m     28\u001b[39m )\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExplicitEnum, TensorType, is_jax_tensor, is_tf_tensor, is_torch_tensor\n",
            "\u001b[36mFile \u001b[39m\u001b[32mD:\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\image_utils.py:84\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_cv2_available():\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_yt_dlp_available():\n",
            "\u001b[36mFile \u001b[39m\u001b[32mD:\\anaconda3\\envs\\capstone\\Lib\\site-packages\\cv2\\__init__.py:12\u001b[39m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmultiarray\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy.core.multiarray'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[486]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BertModel\n\u001b[32m      3\u001b[39m model = BertModel.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mbert-base-uncased\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# outputs = model(input_ids)  # input_ids shape: (batch_size, seq_len)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1229\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mD:\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1852\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1850\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._class_to_module.keys():\n\u001b[32m   1851\u001b[39m     module = \u001b[38;5;28mself\u001b[39m._get_module(\u001b[38;5;28mself\u001b[39m._class_to_module[name])\n\u001b[32m-> \u001b[39m\u001b[32m1852\u001b[39m     value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m   1853\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules:\n\u001b[32m   1854\u001b[39m     value = \u001b[38;5;28mself\u001b[39m._get_module(name)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mD:\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1851\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1849\u001b[39m     value = Placeholder\n\u001b[32m   1850\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._class_to_module.keys():\n\u001b[32m-> \u001b[39m\u001b[32m1851\u001b[39m     module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1852\u001b[39m     value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m   1853\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mD:\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1865\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   1863\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m + module_name, \u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m)\n\u001b[32m   1864\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1865\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1866\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m because of the following error (look up to see its\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1867\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1868\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
            "\u001b[31mRuntimeError\u001b[39m: Failed to import transformers.models.bert.modeling_bert because of the following error (look up to see its traceback):\nNo module named 'numpy.core.multiarray'"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "# outputs = model(input_ids)  # input_ids shape: (batch_size, seq_len)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9da8153-5108-4bf7-8da1-76124a2f3a24",
      "metadata": {
        "id": "e9da8153-5108-4bf7-8da1-76124a2f3a24",
        "outputId": "ca7f5bba-4303-455d-f3d0-8a4b27e8f366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "strart\n",
            "Tags:\n",
            "tensor([[0, 4, 4, 2, 3, 4],\n",
            "        [0, 4, 4, 2, 3, 4],\n",
            "        [4, 4, 4, 2, 3, 4]])\n",
            "Mask:\n",
            "tensor([[ True,  True,  True,  True, False],\n",
            "        [ True,  True,  True,  True,  True]])\n",
            "Tokens:\n",
            "tensor([[[ 0.1054,  0.5158, -0.1154,  0.2473,  0.0839,  0.1271, -0.1564],\n",
            "         [ 0.2386,  0.4579, -0.2578,  0.3971, -0.2138,  0.1635, -0.1007],\n",
            "         [ 0.2685,  0.3010, -0.1350,  0.2836, -0.1957,  0.1078, -0.1129],\n",
            "         [ 0.3029,  0.3788, -0.0396,  0.2126, -0.2045,  0.0870, -0.1658],\n",
            "         [ 0.0869,  0.4848, -0.4288,  0.5283, -0.1605,  0.2429, -0.0614],\n",
            "         [ 0.2137,  0.4056, -0.1671,  0.2671, -0.1420,  0.1801, -0.2401]],\n",
            "\n",
            "        [[ 0.1322,  0.4488, -0.0644,  0.1796,  0.1584,  0.0481, -0.1683],\n",
            "         [ 0.2285,  0.4319, -0.2723,  0.4005, -0.2553,  0.1600, -0.1759],\n",
            "         [ 0.2781,  0.2908, -0.1002,  0.2504, -0.1608,  0.0951, -0.0953],\n",
            "         [ 0.1097,  0.4581, -0.3639,  0.4544, -0.1816,  0.2448, -0.1027],\n",
            "         [ 0.2675,  0.4134, -0.0754,  0.2635, -0.1886,  0.1239, -0.1359],\n",
            "         [ 0.2122,  0.4436, -0.2479,  0.3546, -0.2044,  0.1794, -0.1792]],\n",
            "\n",
            "        [[ 0.2576,  0.3259, -0.1804,  0.2932, -0.2084,  0.1175, -0.1875],\n",
            "         [ 0.2187,  0.3848, -0.2731,  0.3847, -0.2879,  0.1519, -0.2562],\n",
            "         [ 0.2848,  0.2785, -0.0698,  0.2192, -0.1292,  0.0824, -0.0942],\n",
            "         [ 0.2382,  0.3653, -0.1039,  0.2190, -0.2045,  0.1438, -0.2143],\n",
            "         [ 0.1279,  0.4142, -0.3589,  0.4598, -0.2106,  0.2384, -0.1120],\n",
            "         [ 0.2143,  0.3824, -0.1492,  0.2425, -0.1778,  0.1979, -0.3244]]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "the first two dimensions of emissions and mask must match, got (3, 6) and (2, 5)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[134]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m optimizer = torch.optim.Adam(model.parameters(), lr=\u001b[32m0.01\u001b[39m)\n\u001b[32m      3\u001b[39m model = LSTM_CRF()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m loss = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[32m      6\u001b[39m loss.backward()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[132]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mLSTM_CRF.loss\u001b[39m\u001b[34m(self, x, tags, mask)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMask:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmask\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTokens:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m x = -\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcrf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "\u001b[36mFile \u001b[39m\u001b[32mD:\\anaconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mD:\\anaconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mD:\\anaconda3\\envs\\capstone\\Lib\\site-packages\\torchcrf\\__init__.py:90\u001b[39m, in \u001b[36mCRF.forward\u001b[39m\u001b[34m(self, emissions, tags, mask, reduction)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m     64\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     65\u001b[39m         emissions: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m     68\u001b[39m         reduction: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     69\u001b[39m ) -> torch.Tensor:\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the conditional log likelihood of a sequence of tags given emission scores.\u001b[39;00m\n\u001b[32m     71\u001b[39m \n\u001b[32m     72\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     88\u001b[39m \u001b[33;03m        reduction is ``none``, ``()`` otherwise.\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43memissions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m reduction \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtoken_mean\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     92\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33minvalid reduction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreduction\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mD:\\anaconda3\\envs\\capstone\\Lib\\site-packages\\torchcrf\\__init__.py:161\u001b[39m, in \u001b[36mCRF._validate\u001b[39m\u001b[34m(self, emissions, tags, mask)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m emissions.shape[:\u001b[32m2\u001b[39m] != mask.shape:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    162\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mthe first two dimensions of emissions and mask must match, \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    163\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(emissions.shape[:\u001b[32m2\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(mask.shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    164\u001b[39m     no_empty_seq = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m mask[\u001b[32m0\u001b[39m].all()\n\u001b[32m    165\u001b[39m     no_empty_seq_bf = \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m mask[:, \u001b[32m0\u001b[39m].all()\n",
            "\u001b[31mValueError\u001b[39m: the first two dimensions of emissions and mask must match, got (3, 6) and (2, 5)"
          ]
        }
      ],
      "source": [
        "for i in range(20):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    model = LSTM_CRF()\n",
        "    loss = model.loss(encoded, tags, mask)\n",
        "    print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91ac443e-9be0-459f-9e77-5ed6a78fdf0c",
      "metadata": {
        "id": "91ac443e-9be0-459f-9e77-5ed6a78fdf0c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (capstone)",
      "language": "python",
      "name": "capstone"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}